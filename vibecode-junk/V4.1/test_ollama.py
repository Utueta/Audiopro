import requests
import json

def test_ollama_connection():
    url = "http://localhost:11434/api/generate"
    # Modifiez le nom du modÃ¨le si vous utilisez 'mistral' ou 'llama3'
    payload = {
        "model": "llama3", 
        "prompt": "RÃ©ponds 'OK' si tu reÃ§ois ce message.",
        "stream": False
    }

    print("ğŸ” Test de connexion Ã  Ollama...")
    try:
        response = requests.post(url, json=payload, timeout=5)
        if response.status_code == 200:
            print("âœ… Connexion rÃ©ussie !")
            print(f"ğŸ¤– RÃ©ponse du LLM : {response.json().get('response')}")
        else:
            print(f"âš ï¸ Erreur serveur (Code {response.status_code}).")
    except requests.exceptions.ConnectionError:
        print("âŒ Ã‰CHEC : Ollama ne semble pas Ãªtre lancÃ©. (Tapez 'ollama serve' dans un terminal)")
    except Exception as e:
        print(f"âŒ Erreur imprÃ©vue : {e}")

if __name__ == "__main__":
    test_ollama_connection()
